{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/sayem/Desktop/deepHSI\")  # Adjust to your project root path\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Custom module imports\n",
    "from src.dataset.components.hyperspectral_dataset import HyperspectralDataset\n",
    "from src.dataset.components.utils import *\n",
    "from src.dataset.medical_datasets.bloodHSI import BloodDetectionHSIDataModule\n",
    "from src.dataset.remote_sensing_datasets.paviaC import PaviaCDataModule\n",
    "from src.dataset.remote_sensing_datasets.ksc import KSCDataModule\n",
    "from src.models.hsi_classification_module import HSIClassificationLitModule\n",
    "from src.models.components.simple_dense_net import HSIFCModel\n",
    "\n",
    "# PyTorch and metrics imports\n",
    "import torch\n",
    "from torchmetrics import Precision, Recall, F1Score\n",
    "\n",
    "# Importing from `lightning` instead of `pytorch_lightning`\n",
    "import lightning as L\n",
    "# from lightning import Trainer\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Path to the .mat file\n",
    "mat_file_path = '/home/sayem/Desktop/deepHSI/data/PaviaC/PaviaC/Pavia_gt.mat'\n",
    "\n",
    "# Load the .mat file\n",
    "data = loadmat(mat_file_path)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data'  # Specify the directory where you want the data to be downloaded\n",
    "\n",
    "# Include 'batch_size', 'num_workers', and 'num_classes' within the hyperparams dictionary\n",
    "hyperparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 20,\n",
    "    \"patch_size\": 5, \n",
    "    \"center_pixel\": True, \n",
    "    \"supervision\": \"full\",\n",
    "    \"num_classes\": 10  # Define the number of classes in your dataset\n",
    "}\n",
    "\n",
    "# Assuming YourModel is defined elsewhere and num_classes is known\n",
    "input_channels = 102\n",
    "\n",
    "# Define custom metrics for the classification task using the updated hyperparams\n",
    "custom_metrics = {\n",
    "    \"precision\": Precision(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass'),\n",
    "    \"recall\": Recall(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass'),\n",
    "    \"f1\": F1Score(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass')\n",
    "}\n",
    "\n",
    "model = HSIFCModel(\n",
    "    input_channels=input_channels,\n",
    "    patch_size=hyperparams[\"patch_size\"],  # Use patch_size from hyperparams\n",
    "    n_classes=hyperparams[\"num_classes\"],  # Use num_classes from hyperparams\n",
    "    dropout=True\n",
    ")\n",
    "\n",
    "# Initialize the HSIClassificationLitModule with the model and other hyperparameters\n",
    "hsi_module = HSIClassificationLitModule(\n",
    "    net=model,\n",
    "    optimizer_cls=torch.optim.Adam,\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    num_classes=hyperparams[\"num_classes\"],  # Use num_classes from hyperparams\n",
    "    custom_metrics=custom_metrics\n",
    ")\n",
    "\n",
    "# # Initialize the PyTorch Lightning Trainer\n",
    "# trainer = Trainer(max_epochs=10, precision='16-mixed', accelerator='gpu', devices=1)\n",
    "max_epochs = 15\n",
    "\n",
    "# Initialize the PyTorch Lightning Trainer with fast_dev_run enabled\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=False,  # Enable fast_dev_run\n",
    "    precision='16-mixed',  # Use 16-bit precision\n",
    "    accelerator='gpu',  # Specify the accelerator as GPU\n",
    "    max_epochs = max_epochs\n",
    ")\n",
    "\n",
    "# Initialize the PaviaCDataModule with the updated arguments\n",
    "pavia_c_datamodule = PaviaCDataModule(\n",
    "    data_dir=data_dir,\n",
    "    hyperparams=hyperparams  # Pass hyperparams which now includes num_classes\n",
    ")\n",
    "\n",
    "# # # Prepare and set up the data module\n",
    "# pavia_c_datamodule.prepare_data()\n",
    "# pavia_c_datamodule.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the train dataset from the data module\n",
    "# trainer.fit(hsi_module, pavia_c_datamodule.train_dataloader())  \n",
    "trainer.fit(hsi_module, datamodule=pavia_c_datamodule)\n",
    "# Use train_dataloader() instead of train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data'  # Specify the directory where you want the data to be downloaded\n",
    "\n",
    "# Now include 'batch_size' and 'num_workers' within the hyperparams dictionary\n",
    "hyperparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 3,\n",
    "    \"patch_size\": 5, \n",
    "    \"center_pixel\": True, \n",
    "    \"supervision\": \"full\"\n",
    "}\n",
    "\n",
    "# Initialize the PaviaCDataModule with the updated arguments\n",
    "pavia_c_datamodule = PaviaCDataModule(\n",
    "    data_dir=data_dir,\n",
    "    hyperparams=hyperparams\n",
    ")\n",
    "\n",
    "# Prepare and set up the data module\n",
    "pavia_c_datamodule.prepare_data()\n",
    "pavia_c_datamodule.setup(stage='fit')\n",
    "\n",
    "# Assert to make sure the datasets are initialized properly\n",
    "assert pavia_c_datamodule.train_dataset and pavia_c_datamodule.val_dataset, \\\n",
    "    \"Datasets not initialized properly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = pavia_c_datamodule.train_dataloader()\n",
    "val_dataloader = pavia_c_datamodule.val_dataloader()\n",
    "test_dataloader = pavia_c_datamodule.test_dataloader()\n",
    "\n",
    "# Optionally, iterate over a few batches to ensure they're loading correctly\n",
    "for batch in train_dataloader:\n",
    "    x, y = batch\n",
    "    print(x.shape, y.shape)\n",
    "    break  # Just to check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Precision, Recall, F1Score\n",
    "from pytorch_lightning import Trainer\n",
    "from src.models.hsi_classification_module import HSIClassificationLitModule\n",
    "from src.models.components.simple_dense_net import HSIFCModel\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Assuming YourModel is defined elsewhere and num_classes is known\n",
    "input_channels = 103\n",
    "\n",
    "# Define custom metrics for the classification task\n",
    "custom_metrics = {\n",
    "    \"precision\": Precision(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass'),\n",
    "    \"recall\": Recall(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass'),\n",
    "    \"f1\": F1Score(num_classes=hyperparams[\"num_classes\"], average='macro', task='multiclass')\n",
    "}\n",
    "\n",
    "# # Initialize your model\n",
    "# model = HSIFCModel(input_channels=103, n_classes=num_classes)  # Update input_channels accordingly\n",
    "\n",
    "model = HSIFCModel(input_channels=input_channels,\n",
    "                    patch_size=hyperparams[\"patch_size\"], \\\n",
    "                    n_classes=hyperparams[\"num_classes\"], dropout=True)\n",
    "\n",
    "# Initialize the HSIClassificationLitModule with the model and other hyperparameters\n",
    "hsi_module = HSIClassificationLitModule(\n",
    "    model=model,\n",
    "    optimizer_cls=torch.optim.Adam,\n",
    "    optimizer_params={\"lr\": 1e-3},\n",
    "    num_classes=num_classes,\n",
    "    custom_metrics=custom_metrics\n",
    ")\n",
    "\n",
    "# Initialize the PyTorch Lightning Trainer\n",
    "trainer = Trainer(max_epochs=10, \\\n",
    "    precision='16-mixed', accelerator='gpu', devices=1)\n",
    "\n",
    "# Fit the model\n",
    "# Make sure to replace `pavia_c_datamodule` with your actual data module instance\n",
    "trainer.fit(hsi_module, pavia_c_datamodule.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import *\n",
    "import scipy.io\n",
    "\n",
    "# Load the hyperspectral image\n",
    "paviaU_path = '/home/sayem/Desktop/deepHSI/data/PaviaU/PaviaU/PaviaU.mat'\n",
    "paviaU_data = scipy.io.loadmat(paviaU_path)['paviaU']\n",
    "\n",
    "print(paviaU_data.shape)\n",
    "\n",
    "# Load the ground truth\n",
    "paviaU_gt_path = '/home/sayem/Desktop/deepHSI/data/PaviaU/PaviaU/PaviaU_gt.mat'\n",
    "paviaU_gt = scipy.io.loadmat(paviaU_gt_path)['paviaU_gt']\n",
    "\n",
    "\n",
    "# Display the hyperspectral image with the ground truth overlay\n",
    "view = imshow(paviaU_data, (55, 41, 12), classes=paviaU_gt)\n",
    "view.set_display_mode('overlay')\n",
    "view.class_alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data'  # Specify the directory where you want the data to be downloaded\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "hyperparams = {\"patch_size\": 5, \"center_pixel\": True, \"supervision\": \"full\"}\n",
    "\n",
    "ksc_datamodule = KSCDataModule(data_dir=data_dir, batch_size=batch_size, **hyperparams)\n",
    "\n",
    "ksc_datamodule.prepare_data()\n",
    "ksc_datamodule.setup(stage='fit')\n",
    "\n",
    "assert ksc_datamodule.train_dataset and ksc_datamodule.val_dataset, \"Datasets not initialized properly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import *\n",
    "import scipy.io\n",
    "\n",
    "# Load the hyperspectral image\n",
    "ksc_data_path = '/home/sayem/Desktop/deepHSI/data/KSC/KSC/KSC.mat'  # Update this path\n",
    "ksc_data = scipy.io.loadmat(ksc_data_path)['KSC']  # Update 'variable_name' with the actual variable name in your MAT file\n",
    "\n",
    "print(ksc_data.shape)\n",
    "\n",
    "# Load the ground truth\n",
    "ksc_gt_path = '/home/sayem/Desktop/deepHSI/data/KSC/KSC/KSC_gt.mat'  # Update this path\n",
    "ksc_gt = scipy.io.loadmat(ksc_gt_path)['KSC_gt']  # Update 'variable_name' with the actual variable name in your MAT file\n",
    "\n",
    "# Display the hyperspectral image with the ground truth overlay\n",
    "# Update the band numbers (55, 41, 12) according to your dataset's characteristics\n",
    "view = imshow(ksc_data, (43, 21, 11), classes=ksc_gt)\n",
    "view.set_display_mode('overlay')\n",
    "view.class_alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ksc_gt is already loaded and is a numpy array\n",
    "import numpy as np\n",
    "unique_values = np.unique(ksc_gt)\n",
    "\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique values and their counts\n",
    "unique_values, counts = np.unique(ksc_gt, return_counts=True)\n",
    "\n",
    "# Combine unique values and their counts for display\n",
    "unique_values_counts = list(zip(unique_values, counts))\n",
    "\n",
    "unique_values_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data'  # Specify the directory where you want the data to be downloaded\n",
    "doi = '10.5281/zenodo.3984905'  # Specify the DOI for the Zenodo dataset\n",
    "batch_size = 32  # Specify the batch size\n",
    "patch_size = 5  # Specify the patch size\n",
    "\n",
    "# download_from_zenodo(doi, data_dir)\n",
    "\n",
    "\n",
    "# # Instantiate the data module\n",
    "blood_detection_data_module \\\n",
    "    = BloodDetectionHSIDataModule(data_dir, doi, batch_size, patch_size)\n",
    "\n",
    "# Prepare the data (download if necessary)s\n",
    "blood_detection_data_module.prepare_data()\n",
    "\n",
    "# # # Setup the data module (this step usually prepares datasets for training/validation/testing)\n",
    "blood_detection_data_module.setup(stage='fit')\n",
    "\n",
    "# Now you can use the data module to get dataloaders\n",
    "train_dataloader = blood_detection_data_module.train_dataloader()\n",
    "val_dataloader = blood_detection_data_module.val_dataloader()\n",
    "\n",
    "# Example: iterate over the training data\n",
    "for batch in train_dataloader:\n",
    "    x, y = batch  # x is your input data and y is the labels\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "    # Perform your training operations here...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import *\n",
    "import spectral.io.envi as envi\n",
    "\n",
    "name = 'D_1'\n",
    "\n",
    "float_file = f'/home/sayem/Desktop/deepHSI/data/BloodDetectionHSI/HyperBlood/data/{name}.float'\n",
    "hrd_file = f'/home/sayem/Desktop/deepHSI/data/BloodDetectionHSI/HyperBlood/data/{name}.hdr'\n",
    "\n",
    "hs_image = envi.open(hrd_file, float_file)\n",
    "\n",
    "image_data = hs_image.load()\n",
    "\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import imshow\n",
    "\n",
    "band_number = 41  # For example, to view the 10th band\n",
    "view = imshow(image_data[:, :, band_number-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_bands = (51, 41, 9)  # Example band numbers for RGB\n",
    "view = imshow(image_data, bands=rgb_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_file = f'/home/sayem/Desktop/deepHSI/data/BloodDetectionHSI/HyperBlood/anno/{name}.npz'\n",
    "\n",
    "with np.load(anno_file) as data:\n",
    "    annotation = next(iter(data.values()))\n",
    "    print(f\"Loaded annotation data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = imshow(image_data, rgb_bands, classes=annotation)\n",
    "\n",
    "view.set_display_mode('overlay')\n",
    "\n",
    "view.class_alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ksc_gt is already loaded and is a numpy array\n",
    "import numpy as np\n",
    "unique_values = np.unique(annotation)\n",
    "\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique values and their counts\n",
    "unique_values, counts = np.unique(annotation, return_counts=True)\n",
    "\n",
    "# Combine unique values and their counts for display\n",
    "unique_values_counts = list(zip(unique_values, counts))\n",
    "\n",
    "unique_values_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"KSC\"\n",
    "data_dir = Path(\"/home/sayem/Desktop/deepHSI/data\")\n",
    "target_folder = data_dir / dataset_name\n",
    "target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure the dataset is downloaded only once for the session\n",
    "download_dataset(dataset_name, str(target_folder))\n",
    "\n",
    "# Load the dataset components\n",
    "img, gt, label_values, ignored_labels, rgb_bands, _ = load_dataset(\n",
    "    dataset_name, str(target_folder)\n",
    ")\n",
    "\n",
    "hyperparams = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"patch_size\": 4,\n",
    "    \"ignored_labels\": ignored_labels,\n",
    "    \"center_pixel\": True,\n",
    "    \"supervision\": \"full\",\n",
    "}\n",
    "\n",
    "dataset = HyperspectralDataset(img, gt, transform=None, **hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `img` is your 3D image array with shape (512, 217, 204)\n",
    "\n",
    "# Correcting the assumption about the array dimensions:\n",
    "# img.shape = (samples, lines, bands)\n",
    "\n",
    "# Selecting the 100th band from the image\n",
    "# Given the structure, the band data is still the third dimension\n",
    "band_to_plot = img[:, :, 99]  # 99 for the 100th band as indexing starts from 0\n",
    "\n",
    "# Plotting the selected band\n",
    "plt.imshow(band_to_plot, cmap='gray')  # Using 'gray' colormap for the band image\n",
    "plt.colorbar()  # Adds a colorbar to represent the intensity scale of the band\n",
    "plt.title('Band 100')  # Setting the title to indicate the band being plotted\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Assuming `img` is your 3D image array with shape (samples, lines, band\n",
    "# Subfolder for PNG files\n",
    "subfolder = 'bands'\n",
    "os.makedirs(subfolder, exist_ok=True)  # Create the subfolder if it doesn't exist\n",
    "\n",
    "for i in range(img.shape[2]):  # Loop through each band\n",
    "    band_to_plot = img[:, :, i]\n",
    "    \n",
    "    # Plotting the selected band with a heatmap-like colormap\n",
    "    plt.figure(figsize=(10, 4), dpi=200)\n",
    "    plt.imshow(band_to_plot, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Band {i+1}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Define the PNG filename within the subfolder\n",
    "    png_filename = os.path.join(subfolder, f'{i+1}.png')\n",
    "    \n",
    "    # Save the plot as a PNG file in the subfolder\n",
    "    plt.savefig(png_filename, bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `gt` is your 2D ground truth array with shape (512, 217)\n",
    "\n",
    "# Creating a figure and axis for better control\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size for better clarity\n",
    "\n",
    "# Creating a discrete colormap for your 16 classes\n",
    "cmap = plt.get_cmap('tab20', 16)  # 'tab20' colormap with 16 distinct colors\n",
    "\n",
    "# Plotting the ground truth array with the colormap\n",
    "im = ax.imshow(gt, cmap=cmap, vmin=0, vmax=15)  # Ensure vmin and vmax match the range of your classes\n",
    "\n",
    "# Creating a colorbar with a tick for each class\n",
    "# Here, we specify the boundaries and ticks for clarity\n",
    "cbar = fig.colorbar(im, ax=ax, boundaries=np.arange(-0.5, 16, 1), ticks=np.arange(0, 16), fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Class Labels')  # Labeling the color bar\n",
    "cbar.set_ticklabels([f'Class {i}' for i in range(16)])  # Set custom tick labels\n",
    "\n",
    "# Setting the title and axis labels for more informative presentation\n",
    "ax.set_title('Ground Truth Visualization with 16 Classes')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Line Index')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `img` is your 3D hyperspectral image array with shape (lines, samples, bands)\n",
    "\n",
    "# Reshape the image to a 2D array (pixels, bands)\n",
    "lines, samples, bands = img.shape\n",
    "img_reshaped = img.reshape((lines * samples, bands))\n",
    "\n",
    "# Initialize PCA, you can choose the number of components (n_components) based on your needs\n",
    "# For demonstration, let's reduce the bands to 10 principal components\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# Fit and transform the data to reduce dimensions\n",
    "img_pca = pca.fit_transform(img_reshaped)\n",
    "\n",
    "# Reshape the transformed data back to a 3D array (lines, samples, n_components)\n",
    "img_pca_reshaped = img_pca.reshape((lines, samples, pca.n_components))\n",
    "\n",
    "print(img_pca_reshaped.shape)\n",
    "\n",
    "# Visualize the first principal component as an example\n",
    "plt.imshow(img_pca_reshaped[:, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('First Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# You can now use img_pca_reshaped for further analysis or classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `img` is your 3D hyperspectral image array with shape (lines, samples, bands)\n",
    "# And assuming you have a corresponding label array `labels` with the shape (lines, samples)\n",
    "\n",
    "# Reshape the image to a 2D array (pixels, bands)\n",
    "lines, samples, bands = img.shape\n",
    "img_reshaped = img.reshape((lines * samples, bands))\n",
    "\n",
    "# Also, reshape the labels to a 1D array\n",
    "labels_reshaped = gt.reshape((lines * samples,))\n",
    "\n",
    "# Split the data and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(img_reshaped, labels_reshaped, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes PCA and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'pca__n_components': [50, 100, 150],  # Number of principal components to try\n",
    "    'knn__n_neighbors': [3, 5, 7]  # Number of neighbors for KNN\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation score: {grid_search.best_score_:.2f}')\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the best estimator on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA on the entire dataset with the best number of components\n",
    "best_pca = PCA(n_components=grid_search.best_params_['pca__n_components'])\n",
    "img_pca_full = best_pca.fit_transform(img_reshaped)\n",
    "\n",
    "# Extract the first principal component\n",
    "first_pc_full = img_pca_full[:, 0]\n",
    "\n",
    "# Reshape the first principal component to the original spatial dimensions\n",
    "first_pc_reshaped = first_pc_full.reshape(lines, samples)\n",
    "\n",
    "# Visualize the first principal component\n",
    "plt.imshow(first_pc_reshaped, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('First Principal Component with Best PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepHSI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
