{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    \"/home/sayem/Desktop/deepHSI\"\n",
    ")  # Replace this with the actual path to your project root\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Now you should be able to import your custom modules\n",
    "from src.dataset.components.hyperspectral_dataset import HyperspectralDataset\n",
    "from src.dataset.components.utils import *\n",
    "\n",
    "from src.dataset.hyperspectral_datamodule import \\\n",
    "    BloodDetectionHSIDataModule  # Adjust the import path according to your project structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'BloodDetectionHSI' already exists at /home/sayem/Desktop/deepHSI/data/BloodDetectionHSI. Checking for ZIP files...\n",
      "Contents of /home/sayem/Desktop/deepHSI/data/BloodDetectionHSI:\n",
      " - HyperBlood\n",
      "Loaded hyperspectral image data.\n",
      "Loaded annotation data.\n",
      "torch.Size([32, 1, 128, 5, 5])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data'  # Specify the directory where you want the data to be downloaded\n",
    "doi = '10.5281/zenodo.3984905'  # Specify the DOI for the Zenodo dataset\n",
    "batch_size = 32  # Specify the batch size\n",
    "patch_size = 5  # Specify the patch size\n",
    "\n",
    "# download_from_zenodo(doi, data_dir)\n",
    "\n",
    "\n",
    "# # Instantiate the data module\n",
    "blood_detection_data_module \\\n",
    "    = BloodDetectionHSIDataModule(data_dir, doi, batch_size, patch_size)\n",
    "\n",
    "# Prepare the data (download if necessary)\n",
    "blood_detection_data_module.prepare_data()\n",
    "\n",
    "# # # Setup the data module (this step usually prepares datasets for training/validation/testing)\n",
    "blood_detection_data_module.setup(stage='fit')\n",
    "\n",
    "# Now you can use the data module to get dataloaders\n",
    "train_dataloader = blood_detection_data_module.train_dataloader()\n",
    "val_dataloader = blood_detection_data_module.val_dataloader()\n",
    "\n",
    "# Example: iterate over the training data\n",
    "for batch in train_dataloader:\n",
    "    x, y = batch  # x is your input data and y is the labels\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "    # Perform your training operations here...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import spectral.io.envi as envi\n",
    "\n",
    "def load_random_pair(data_dir, anno_dir):\n",
    "    # List all hyperspectral image files\n",
    "    hs_files = glob.glob(os.path.join(data_dir, '*.float'))\n",
    "\n",
    "    # Randomly pick one hyperspectral image\n",
    "    selected_hs_file = random.choice(hs_files)\n",
    "    base_name = os.path.basename(selected_hs_file).split('.')[0]\n",
    "\n",
    "    # Construct the corresponding annotation file path\n",
    "    anno_file = os.path.join(anno_dir, f\"{base_name}.npz\")\n",
    "\n",
    "    # Read the hyperspectral image\n",
    "    hdr_file_path = selected_hs_file.replace('.float', '.hdr')\n",
    "    hs_image = envi.open(hdr_file_path, selected_hs_file)\n",
    "    image_data = hs_image.load()\n",
    "\n",
    "    # Load the annotation\n",
    "    if os.path.exists(anno_file):\n",
    "        with np.load(anno_file) as data:\n",
    "            # Assuming .npz file contains only one array, directly access it\n",
    "            # Note: This assumes the .npz file contains only one array and may not work \n",
    "            # if there are multiple arrays\n",
    "            annotation = next(iter(data.values()))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Annotation file not found: {anno_file}\")\n",
    "\n",
    "    return image_data, annotation\n",
    "\n",
    "# Base paths for the data and annotations\n",
    "data_dir = '/home/sayem/Desktop/deepHSI/data/BloodDetectionHSI/HyperBlood/data'\n",
    "anno_dir = '/home/sayem/Desktop/deepHSI/data/BloodDetectionHSI/HyperBlood/anno'\n",
    "\n",
    "# Load a random pair of hyperspectral image and its annotation\n",
    "image_data, annotation = load_random_pair(data_dir, anno_dir)\n",
    "\n",
    "# Now, you can use `image_data` (the hyperspectral image) and \n",
    "# `annotation` (the corresponding annotation) for your processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 696, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 696)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"KSC\"\n",
    "data_dir = Path(\"/home/sayem/Desktop/deepHSI/data\")\n",
    "target_folder = data_dir / dataset_name\n",
    "target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure the dataset is downloaded only once for the session\n",
    "download_dataset(dataset_name, str(target_folder))\n",
    "\n",
    "# Load the dataset components\n",
    "img, gt, label_values, ignored_labels, rgb_bands, _ = load_dataset(\n",
    "    dataset_name, str(target_folder)\n",
    ")\n",
    "\n",
    "hyperparams = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"patch_size\": 4,\n",
    "    \"ignored_labels\": ignored_labels,\n",
    "    \"center_pixel\": True,\n",
    "    \"supervision\": \"full\",\n",
    "}\n",
    "\n",
    "dataset = HyperspectralDataset(img, gt, transform=None, **hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `img` is your 3D image array with shape (512, 217, 204)\n",
    "\n",
    "# Correcting the assumption about the array dimensions:\n",
    "# img.shape = (samples, lines, bands)\n",
    "\n",
    "# Selecting the 100th band from the image\n",
    "# Given the structure, the band data is still the third dimension\n",
    "band_to_plot = img[:, :, 99]  # 99 for the 100th band as indexing starts from 0\n",
    "\n",
    "# Plotting the selected band\n",
    "plt.imshow(band_to_plot, cmap='gray')  # Using 'gray' colormap for the band image\n",
    "plt.colorbar()  # Adds a colorbar to represent the intensity scale of the band\n",
    "plt.title('Band 100')  # Setting the title to indicate the band being plotted\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Assuming `img` is your 3D image array with shape (samples, lines, band\n",
    "# Subfolder for PNG files\n",
    "subfolder = 'bands'\n",
    "os.makedirs(subfolder, exist_ok=True)  # Create the subfolder if it doesn't exist\n",
    "\n",
    "for i in range(img.shape[2]):  # Loop through each band\n",
    "    band_to_plot = img[:, :, i]\n",
    "    \n",
    "    # Plotting the selected band with a heatmap-like colormap\n",
    "    plt.figure(figsize=(10, 4), dpi=200)\n",
    "    plt.imshow(band_to_plot, cmap='coolwarm', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Band {i+1}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Define the PNG filename within the subfolder\n",
    "    png_filename = os.path.join(subfolder, f'{i+1}.png')\n",
    "    \n",
    "    # Save the plot as a PNG file in the subfolder\n",
    "    plt.savefig(png_filename, bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `gt` is your 2D ground truth array with shape (512, 217)\n",
    "\n",
    "# Creating a figure and axis for better control\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Increase figure size for better clarity\n",
    "\n",
    "# Creating a discrete colormap for your 16 classes\n",
    "cmap = plt.get_cmap('tab20', 16)  # 'tab20' colormap with 16 distinct colors\n",
    "\n",
    "# Plotting the ground truth array with the colormap\n",
    "im = ax.imshow(gt, cmap=cmap, vmin=0, vmax=15)  # Ensure vmin and vmax match the range of your classes\n",
    "\n",
    "# Creating a colorbar with a tick for each class\n",
    "# Here, we specify the boundaries and ticks for clarity\n",
    "cbar = fig.colorbar(im, ax=ax, boundaries=np.arange(-0.5, 16, 1), ticks=np.arange(0, 16), fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Class Labels')  # Labeling the color bar\n",
    "cbar.set_ticklabels([f'Class {i}' for i in range(16)])  # Set custom tick labels\n",
    "\n",
    "# Setting the title and axis labels for more informative presentation\n",
    "ax.set_title('Ground Truth Visualization with 16 Classes')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Line Index')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `img` is your 3D hyperspectral image array with shape (lines, samples, bands)\n",
    "\n",
    "# Reshape the image to a 2D array (pixels, bands)\n",
    "lines, samples, bands = img.shape\n",
    "img_reshaped = img.reshape((lines * samples, bands))\n",
    "\n",
    "# Initialize PCA, you can choose the number of components (n_components) based on your needs\n",
    "# For demonstration, let's reduce the bands to 10 principal components\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# Fit and transform the data to reduce dimensions\n",
    "img_pca = pca.fit_transform(img_reshaped)\n",
    "\n",
    "# Reshape the transformed data back to a 3D array (lines, samples, n_components)\n",
    "img_pca_reshaped = img_pca.reshape((lines, samples, pca.n_components))\n",
    "\n",
    "print(img_pca_reshaped.shape)\n",
    "\n",
    "# Visualize the first principal component as an example\n",
    "plt.imshow(img_pca_reshaped[:, :, 0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('First Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# You can now use img_pca_reshaped for further analysis or classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `img` is your 3D hyperspectral image array with shape (lines, samples, bands)\n",
    "# And assuming you have a corresponding label array `labels` with the shape (lines, samples)\n",
    "\n",
    "# Reshape the image to a 2D array (pixels, bands)\n",
    "lines, samples, bands = img.shape\n",
    "img_reshaped = img.reshape((lines * samples, bands))\n",
    "\n",
    "# Also, reshape the labels to a 1D array\n",
    "labels_reshaped = gt.reshape((lines * samples,))\n",
    "\n",
    "# Split the data and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(img_reshaped, labels_reshaped, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes PCA and KNN classifier\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'pca__n_components': [50, 100, 150],  # Number of principal components to try\n",
    "    'knn__n_neighbors': [3, 5, 7]  # Number of neighbors for KNN\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation score: {grid_search.best_score_:.2f}')\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the best estimator on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA on the entire dataset with the best number of components\n",
    "best_pca = PCA(n_components=grid_search.best_params_['pca__n_components'])\n",
    "img_pca_full = best_pca.fit_transform(img_reshaped)\n",
    "\n",
    "# Extract the first principal component\n",
    "first_pc_full = img_pca_full[:, 0]\n",
    "\n",
    "# Reshape the first principal component to the original spatial dimensions\n",
    "first_pc_reshaped = first_pc_full.reshape(lines, samples)\n",
    "\n",
    "# Visualize the first principal component\n",
    "plt.imshow(first_pc_reshaped, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('First Principal Component with Best PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepHSI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
