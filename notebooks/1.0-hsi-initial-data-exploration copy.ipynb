{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sayem/Desktop/deepHSI/notebooks', '/home/sayem/anaconda3/envs/deepHSI/lib/python312.zip', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12/lib-dynload', '', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12/site-packages']\n",
      "['/home/sayem/Desktop/deepHSI/notebooks', '/home/sayem/anaconda3/envs/deepHSI/lib/python312.zip', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12/lib-dynload', '', '/home/sayem/anaconda3/envs/deepHSI/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)  # This will print the list of paths where Python looks for modules\n",
    "\n",
    "import sys\n",
    "\n",
    "# Try importing your package\n",
    "import deepHSI\n",
    "\n",
    "print(sys.path)  # This will print the list of paths where Python looks for modules\n",
    "\n",
    "# Try importing your package\n",
    "import deepHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/sayem/Desktop/deepHSI\")  # Adjust to your project root path\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "\n",
    "# Custom module imports\n",
    "from deepHSI.dataset.components.hyperspectral_dataset import HyperspectralDataset\n",
    "from deepHSI.dataset.components.utils import *\n",
    "from deepHSI.dataset.medical_datasets.bloodHSI import BloodDetectionHSIDataModule\n",
    "from deepHSI.dataset.remote_sensing_datasets.ksc import KSCDataModule\n",
    "from deepHSI.dataset.remote_sensing_datasets.paviaC import PaviaCDataModule\n",
    "from deepHSI.models.components.simple_dense_net import HSIFCModel, HSIFCResNetModel\n",
    "from deepHSI.models.hsi_classification_module import HSIClassificationLitModule\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "# Importing from `lightning` instead of `pytorch_lightning`\n",
    "import lightning as L\n",
    "\n",
    "# PyTorch and metrics imports\n",
    "import torch\n",
    "from torchmetrics import F1Score, Precision, Recall\n",
    "\n",
    "# from lightning import Trainer\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Specify the directory to save checkpoints\n",
    "ckpt_dir = Path(\"/home/sayem/Desktop/deepHSI/notebooks/ckpt\")\n",
    "\n",
    "# Function to clear directory\n",
    "\n",
    "\n",
    "def clear_directory(path: Path):\n",
    "    if path.is_dir():\n",
    "        for item in path.iterdir():\n",
    "            if item.is_dir():\n",
    "                clear_directory(item)\n",
    "                item.rmdir()\n",
    "            else:\n",
    "                item.unlink()\n",
    "    else:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Clear and/or create the log and checkpoint directories\n",
    "clear_directory(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import loadmat\n",
    "\n",
    "# # Path to the .mat file\n",
    "# mat_file_path = \"/home/sayem/Desktop/deepHSI/data/PaviaC/PaviaC/Pavia_gt.mat\"\n",
    "\n",
    "# # Load the .mat file\n",
    "# data = loadmat(mat_file_path)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the data module\n",
    "data_dir = \"/home/sayem/Desktop/deepHSI/data\"  # Specify the directory where you want the data to be downloaded\n",
    "\n",
    "# Include 'batch_size', 'num_workers', and 'num_classes' within the hyperparams dictionary\n",
    "hyperparams = {\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 24,\n",
    "    \"patch_size\": 10,\n",
    "    \"center_pixel\": True,\n",
    "    \"supervision\": \"full\",\n",
    "    \"num_classes\": 10,  # Define the number of classes in your dataset\n",
    "}\n",
    "\n",
    "# Assuming YourModel is defined elsewhere and num_classes is known\n",
    "input_channels = 102\n",
    "\n",
    "# Define custom metrics for the classification task using the updated hyperparams\n",
    "custom_metrics = {\n",
    "    \"precision\": Precision(\n",
    "        num_classes=hyperparams[\"num_classes\"], average=\"macro\", task=\"multiclass\"\n",
    "    ),\n",
    "    \"recall\": Recall(num_classes=hyperparams[\"num_classes\"], average=\"macro\", task=\"multiclass\"),\n",
    "    \"f1\": F1Score(num_classes=hyperparams[\"num_classes\"], average=\"macro\", task=\"multiclass\"),\n",
    "}\n",
    "\n",
    "model = HSIFCResNetModel(\n",
    "    input_channels=input_channels,\n",
    "    patch_size=hyperparams[\"patch_size\"],  # Use patch_size from hyperparams\n",
    "    n_classes=hyperparams[\"num_classes\"],  # Use num_classes from hyperparams\n",
    "    dropout=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk61\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /home/sayem/Desktop/deepHSI/notebooks/wandb/wandb/ wasn't writable, using system temp directory.\n",
      "wandb: WARNING Path /home/sayem/Desktop/deepHSI/notebooks/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20240331_233527-kam0ng09</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/k61/PaviaC/runs/kam0ng09/workspace' target=\"_blank\">Run-Baseline</a></strong> to <a href='https://wandb.ai/k61/PaviaC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/k61/PaviaC' target=\"_blank\">https://wandb.ai/k61/PaviaC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/k61/PaviaC/runs/kam0ng09/workspace' target=\"_blank\">https://wandb.ai/k61/PaviaC/runs/kam0ng09/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"1.0-hsi-initial-data-exploration.ipynb\"\n",
    "\n",
    "wandb.login()\n",
    "# Initialize WandbLogger with more control and a meaningful run name\n",
    "wandb_logger = WandbLogger(\n",
    "    name=f\"Run-Baseline\",  # Custom run name with a meaningful trailing name\n",
    "    project=\"PaviaC\",  # Your project name\n",
    "    save_dir=\"/home/sayem/Desktop/deepHSI/notebooks/wandb\",  # Directory to save logs\n",
    "    offline=False,  # Set to True if you want to run offline and upload later\n",
    "    id=None,  # Can set a specific ID for the run, useful for resuming\n",
    "    anonymous=False,  # Set to True to anonymously log data\n",
    "    log_model=\"all\",  # Log all checkpoints during training\n",
    "    # prefix=\"my_experiment_\",  # Prefix for all logged metrics\n",
    "    # Additional Wandb init arguments\n",
    "    tags=[\"ResNet50\", \"without-scheduler\"],  # Tags for the run\n",
    "    # group=\"experiment_group\",  # Group under which to organize the run\n",
    "    # notes=\"Testing different architectures on the PaviaC dataset\",  # Notes about the run\n",
    "    # # More kwargs can be added as needed\n",
    ")\n",
    "\n",
    "# add your batch size to the wandb config\n",
    "wandb_logger.experiment.config[\"batch_size\"] = hyperparams[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "# Hyperparameters from your YAML configuration\n",
    "lr = 0.001  # learning rate\n",
    "weight_decay = 0.0  # weight decay\n",
    "\n",
    "# 'partial' creates a new function that when called will behave like 'torch.optim.Adam'\n",
    "# with the given 'lr' and 'weight_decay' parameters pre-filled\n",
    "optimizer = partial(torch.optim.Adam, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Since 'optimizer_func' is a function created by 'partial', it won't be an instance of 'torch.optim.Optimizer'\n",
    "# Therefore, the isinstance check is not applicable here. We can check if it's callable instead:\n",
    "assert callable(optimizer)\n",
    "\n",
    "# scheduler = partial(\n",
    "#     torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "#     mode=\"min\",\n",
    "#     factor=0.1,\n",
    "#     patience=10,\n",
    "#     threshold=0.0001,\n",
    "#     threshold_mode=\"rel\",\n",
    "#     cooldown=0,\n",
    "#     min_lr=0,\n",
    "#     eps=1e-08,\n",
    "# )\n",
    "scheduler = None\n",
    "# Since 'scheduler_func' is also a function created by 'partial', we check if it's callable:\n",
    "# assert callable(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Initialize the HSIClassificationLitModule with the model and other hyperparameters\n",
    "hsi_classifier = HSIClassificationLitModule(\n",
    "    net=model,  # Your model instance\n",
    "    optimizer=optimizer,  # The Adam optimizer class from torch.optim\n",
    "    scheduler=scheduler,  # The ReduceLROnPlateau scheduler class from torch.optim.lr_scheduler\n",
    "    loss_fn=torch.nn.functional.cross_entropy,  # Using cross-entropy loss function\n",
    "    num_classes=hyperparams[\"num_classes\"],  # Number of classes from your hyperparameters\n",
    "    custom_metrics=custom_metrics,  # Custom metrics dictionary if any\n",
    ")\n",
    "\n",
    "# # Initialize the PyTorch Lightning Trainer\n",
    "# trainer = Trainer(max_epochs=10, precision='16-mixed', accelerator='gpu', devices=1)\n",
    "max_epochs = 200\n",
    "\n",
    "# Initialize the PaviaCDataModule with the updated arguments\n",
    "pavia_c_datamodule = PaviaCDataModule(\n",
    "    data_dir=data_dir, hyperparams=hyperparams  # Pass hyperparams which now includes num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "# Define the EarlyStopping callback\n",
    "early_stop_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"val/f1\",  # Specify the metric to monitor\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=True,  # Whether to print logs to stdout\n",
    "    mode=\"max\",  # In 'min' mode, training will stop when the quantity monitored has stopped decreasing\n",
    "    check_on_train_epoch_end=False,\n",
    ")\n",
    "\n",
    "# from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "model_checkpoint = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val/f1\",  # Metric to monitor\n",
    "    dirpath=str(ckpt_dir),  # Convert Path object to string, Directory to save checkpoints\n",
    "    filename=\"best-checkpoint-{epoch:02d}-{val/f1:.2f}\",  # Checkpoint file name\n",
    "    save_top_k=1,  # Save only the best checkpoint\n",
    "    mode=\"max\",  # 'max' because we want to maximize 'val/f1'\n",
    "    verbose=True,  # Print a message when a new best is found\n",
    "    auto_insert_metric_name=False,  # Prevents metric names being inserted into filename automatically\n",
    ")\n",
    "\n",
    "rich_pbar_callback = L.pytorch.callbacks.RichProgressBar(\n",
    "    refresh_rate=1,\n",
    "    leave=True,\n",
    ")\n",
    "\n",
    "lr_monitor_callback = L.pytorch.callbacks.LearningRateMonitor(logging_interval='epoch') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepHSI.utils.custom_callbacks.confusion_matrix_callback import (\n",
    "    ConfusionMatrixLoggerCallBack,\n",
    ")\n",
    "\n",
    "confusion_matrix_callback = ConfusionMatrixLoggerCallBack()\n",
    "\n",
    "from deepHSI.utils.custom_callbacks.lr_finder_callback import (\n",
    "    DynamicLRFinder,\n",
    "    InitialLRFinder,\n",
    ")\n",
    "\n",
    "\n",
    "from deepHSI.utils.custom_callbacks.batch_size_finder_callback import InitialBatchSizeFinder\n",
    "# # Instantiate the DynamicLRFinder callback with the defined milestones\n",
    "# dynamic_lr_finder = InitialLRFinder(min_lr=1e-8, max_lr=1, \\\n",
    "#     num_training_steps=100, mode='exponential')\n",
    "\n",
    "# Instantiate the DynamicLRFinder callback with the defined milestones\n",
    "lr_finder_callback = InitialLRFinder()\n",
    "batch_finder_callback = InitialBatchSizeFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PyTorch Lightning Trainer with fast_dev_run enabled\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=False,  # Enable fast_dev_run\n",
    "    precision=\"16-mixed\",  # Use 16-bit precision\n",
    "    accelerator=\"auto\",  # Specify the accelerator as GPU\n",
    "    max_epochs=max_epochs,\n",
    "    log_every_n_steps=3,\n",
    "    callbacks=[\n",
    "        lr_finder_callback,\n",
    "        early_stop_callback,\n",
    "        model_checkpoint,\n",
    "        confusion_matrix_callback,\n",
    "        # batch_finder_callback,\n",
    "        lr_monitor_callback,\n",
    "    ],  # rich_pbar_callback],\n",
    "    logger=wandb_logger,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'PaviaC' already exists. Skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | net       | HSIFCResNetModel    | 44.8 M\n",
      "1 | precision | MulticlassPrecision | 0     \n",
      "2 | recall    | MulticlassRecall    | 0     \n",
      "3 | f1        | MulticlassF1Score   | 0     \n",
      "--------------------------------------------------\n",
      "44.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.8 M    Total params\n",
      "179.275   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c09bb381dc41c69f36e78b4584b15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c46b221fb1d48389d920bc81d488a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a152d58da604fee8d93c85625bb8687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayem/anaconda3/envs/deepHSI/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "LR finder stopped early after 80 steps due to diverging loss.\n",
      "Learning rate set to 2.2908676527677725e-05\n",
      "Restoring states from the checkpoint path at /home/sayem/Desktop/deepHSI/notebooks/.lr_find_b31db25a-8765-4b2e-900b-111f9b5a58b1.ckpt\n",
      "Restored all states from the checkpoint at /home/sayem/Desktop/deepHSI/notebooks/.lr_find_b31db25a-8765-4b2e-900b-111f9b5a58b1.ckpt\n",
      "Epoch 0, global step 8275: 'val/f1' reached 0.17001 (best 0.17001), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-00-0.17-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e283e014be4b07af085db4bd884c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/f1 improved. New best score: 0.483\n",
      "Epoch 1, global step 16630: 'val/f1' reached 0.48256 (best 0.48256), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-01-0.48-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b43233ce014678b2b9a44d06775782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 24985: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aba5e99a3d2455182c5d4107609cbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 33340: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123179bf37cb4723add9462928b19416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/f1 improved by 0.007 >= min_delta = 0.0. New best score: 0.490\n",
      "Epoch 4, global step 41695: 'val/f1' reached 0.48982 (best 0.48982), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-04-0.49-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1597636dcdb41feb5ce3d486b612be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/f1 improved by 0.088 >= min_delta = 0.0. New best score: 0.578\n",
      "Epoch 5, global step 50050: 'val/f1' reached 0.57769 (best 0.57769), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-05-0.58-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f03e7731e6f4482846428041d83d41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 58405: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09571fcd1b834d2f8ec1c3ac602bfefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 66760: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0241843446814fd68e9dccd1ead4647b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 75115: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9932ea09027a4ae28bb56db9aef42ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 83470: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a372231217284fa5b1855ba9c5637a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 91825: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f4fa03628d4b24a2da02f067b565e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 100180: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c52cc153a74b8a80b8b10a80ab8919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 108535: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebee7e977bb1417f8b0f33bd8960dc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 116890: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20420780f46c4f6fb266a4cc109b53a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/f1 improved by 0.033 >= min_delta = 0.0. New best score: 0.611\n",
      "Epoch 14, global step 125245: 'val/f1' reached 0.61116 (best 0.61116), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-14-0.61-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f036afef34a4da9bc3b0cb095f0ca29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 133600: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdf6f4e1d62448cadec095adce061cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 141955: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2a15f5238e46099abafcaab50cb21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 150310: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137ea898fc74bf89c0bbc2723450d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/f1 improved by 0.035 >= min_delta = 0.0. New best score: 0.646\n",
      "Epoch 18, global step 158665: 'val/f1' reached 0.64628 (best 0.64628), saving model to '/home/sayem/Desktop/deepHSI/notebooks/ckpt/best-checkpoint-18-0.65-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad07297b81b4a4690bebc4aaa3773dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 167020: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee23cd063b04c5dac1a7939a6aacfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 175375: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93bf855e6a24cb8913c129ff2167cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 183730: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82048b741a4845678176c42a78bb05ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 192085: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a6201667b4e48b85189abfd129860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 200440: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddf8e68f0b4199b76df1b27fccd7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 208795: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91f0021691849dfa3cd4500b6bc2a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 217150: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32b361c039f429bac2ac55dec975005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 225505: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e292a55c05da46c3a45d9d2cd8c69f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 233860: 'val/f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731c872669894956a45a8067b3e8732b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/f1 did not improve in the last 10 records. Best score: 0.646. Signaling Trainer to stop.\n",
      "Epoch 28, global step 242215: 'val/f1' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(hsi_classifier, datamodule=pavia_c_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'PaviaC' already exists. Skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30357f5f51a244718a42f512ef2ec5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_preds_np shape: (114576,), first few elements: [0 1 0 0 0]\n",
      "test_targets_np shape: (114576,), first few elements: [0 1 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.572696328163147     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6008676886558533     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5687479972839355     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.572696328163147    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test/precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6008676886558533    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5687479972839355    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model using the train dataset from the data module\n",
    "dictionary = trainer.test(hsi_classifier, pavia_c_datamodule, verbose=True)\n",
    "# trainer.fit(hsi_module, datamodule=pavia_c_datamodule)\n",
    "# Use train_dataloader() instead of train_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepHSI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
