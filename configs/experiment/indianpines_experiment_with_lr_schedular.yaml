# @package _global_

# To execute this experiment run:
# python train.py experiment=indianpines_experiment

defaults:
  - override /data: indianpines_datamodule
  - override /model: indianpines_model  # Ensure this points to the correct model config file
  # - override /callbacks: default
  # - override /trainer: default

# All parameters below will be merged with parameters from default configurations set above
# This allows you to overwrite only specified parameters

tags: ["idnianpines", "baseline", "with-lr-schedular"]

# seed: 12345
model:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10

trainer:
  min_epochs: 10
  max_epochs: 100
  gradient_clip_val: 0.5

logger:
  wandb:
    _target_: lightning.pytorch.loggers.WandbLogger
    save_dir: "/media/sayem/510B93E12554BBD1/wandb/"
    name: "Run-run_name"
    project: "IndianPines"